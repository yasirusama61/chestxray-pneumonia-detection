# ğŸ« Pneumonia Chest X-Ray Classifier with Deep Learning

[![Made with TensorFlow](https://img.shields.io/badge/Made%20with-TensorFlow-orange?style=flat&logo=tensorflow)](https://www.tensorflow.org/)
[![Model: CNN + Transformer](https://img.shields.io/badge/Model-CNN%20+%20Transformer-blue?style=flat)]()
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Kaggle Dataset](https://img.shields.io/badge/Data-Kaggle-blue?logo=kaggle)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
[![Last Updated](https://img.shields.io/badge/Last%20Updated-April%202025-lightgrey)]()

> A clinically-inspired deep learning pipeline for automated pneumonia detection using chest radiographs â€” integrating CNNs, Transformer-based models, Grad-CAM explainability, and generalization analysis across datasets.

---

## ğŸ”¬ Project Summary

This repository presents a full-scale deep learning solution for pneumonia classification using chest X-ray imaging. It combines:

- âœ… Baseline CNNs  
- ğŸ” Transfer learning (DenseNet121 a.k.a. CheXNet)  
- ğŸš€ Transformer-integrated hybrid architectures  
- ğŸ§  Attention and Grad-CAM visualizations  
- ğŸ§ª Generalization tests on external datasets  

The project is designed to be clinically applicable and interpretable, supporting further research in medical AI and radiographic analysis.

---

## ğŸ“‚ Datasets Used

We train and evaluate on two publicly available datasets:

1. [Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
2. [Chest X-ray (COVID-19, Pneumonia & Tuberculosis)](https://www.kaggle.com/datasets/aysendegerli/chest-xray-pneumoniacovid19tuberculosis)

---

## ğŸ’¡ Clinical Motivation

> Pneumonia is a leading cause of morbidity worldwide, particularly in pediatric and elderly populations. Prompt and accurate detection via chest radiographs is critical â€” and automation can significantly aid in triage, especially in resource-limited settings.

This project leverages modern vision architectures and interpretability tools to build a robust, transparent pneumonia detection system.

---

## ğŸ§  Goals

- Develop high-performance models (CNN, DenseNet, CNN+Transformer, Swin)
- Benchmark against medical-grade datasets
- Visualize model attention and failure modes
- Test generalization on unseen real-world data

---

## ğŸ“ Dataset

The dataset is structured into `train`, `val`, and `test` folders:



ğŸ“¦ Total images: ~5,800  
ğŸ“Š Format: JPEG grayscale chest X-ray images

---

## ğŸ–¼ï¸ Sample Images

<p align="center">
  <img src="assets/sample_train_grid.png" alt="Sample TRAIN Images" width="90%">
</p>

Above are sample chest X-ray images from the training dataset:
- The **top row** shows healthy (Normal) lungs.
- The **bottom row** shows lungs diagnosed with **Pneumonia**.

These images highlight the visual features used by the model to learn pathology patterns.

## ğŸ“Š Class Distribution

<p align="center">
  <img src="assets/class_distribution.png" alt="Class Distribution Across Splits" width="95%">
</p>

This bar chart illustrates the number of X-ray images per class (NORMAL vs. PNEUMONIA) across different dataset splits:

- **Training Set** shows moderate class imbalance (more pneumonia cases).
- **Validation Set** is balanced.
- **Test Set** also has more pneumonia cases.

Understanding class distribution is crucial for handling bias and ensuring balanced evaluation.


## ğŸ§  Model Architecture

A simple **CNN** with:

- 3 Ã— Conv2D layers with ReLU
- MaxPooling after each conv
- Dense + Dropout
- Sigmoid output for binary classification

Want more power? You can upgrade to **EfficientNet**, **ResNet**, or **Transfer Learning**.

---

## ğŸš€ Training

```bash
python train_cnn.py
```
## ğŸ“ˆ Model Evaluation

We evaluated our trained CNN model on the test set from the **Chest X-Ray Pneumonia** dataset. The results demonstrate strong performance in detecting pneumonia from chest X-rays.

### ğŸ§ª Performance Metrics

- **AUC (ROC):** 0.96
- **Precision, Recall, and F1-score** are also high, as shown below.

### ğŸ“Š Confusion Matrix, ROC Curve, and Precision-Recall Curve

The following plot summarizes model performance visually:

![Evaluation Metrics](assets/evaluation_metrics.png) <!-- Replace with actual path if hosted -->

- The model has high **true positive rate** and low **false positive rate**.
- Precision and recall trade-off is strong across thresholds.

### ğŸ©» Example Predictions on Test Images

Below are a few examples from the test set:

![Predictions](assets/sample_predictions.png) <!-- Replace with actual path if hosted -->

The predictions match the ground truth, showing the model's ability to distinguish between **NORMAL** and **PNEUMONIA** chest X-rays effectively.

---

## ğŸ“ˆ Model Comparison: Custom CNN vs DenseNet121 (Transfer Learning)

We trained and evaluated two models on the Chest X-ray Pneumonia dataset:

- âœ… A custom CNN trained from scratch  
- âœ… A transfer learning model using **DenseNet121** pretrained on ImageNet

---

### ğŸ”¬ Evaluation Metrics

| Metric              | Custom CNN       | DenseNet121 (Transfer Learning) |
|---------------------|------------------|---------------------------------|
| **Test Accuracy**   | ~96%             | **87%**                         |
| **ROC AUC**         | 0.9600           | **0.9481**                      |
| **F1-score (Normal)** | 0.85           | **0.81**                        |
| **F1-score (Pneumonia)** | 0.92       | **0.90**                        |
| **Recall (Pneumonia)**  | 0.96        | **0.94**                        |
| **Model Size**      | Small            | Larger                          |
| **Grad-CAM Support**| âœ… Enabled       | âœ… Planned                      |

---

### ğŸ“Š DenseNet121 â€“ Evaluation Results

![DenseNet121 Evaluation](assets/densenet_eval.png)

![Classification Report](assets/densenet_classification_report.png)

- **Confusion Matrix** and ROC curve show reliable classification performance.
- **Classification Report** shows strong recall for PNEUMONIA class (0.94), with slightly lower recall on NORMAL class (0.75).
- F1-score balances out at **0.90 (Pneumonia)** and **0.81 (Normal)**.

---

### ğŸ§  Insight

Despite being a powerful pretrained architecture, DenseNet121 slightly underperformed the custom CNN on this dataset. This may be due to:
- The relatively small dataset size
- The model being frozen during training (not fine-tuned)

---

### ğŸ› ï¸ Next Steps

- âœ… Grad-CAM visualization for DenseNet121
- ğŸ” Fine-tune top layers of DenseNet for better generalization
- ğŸ“¦ Package the best model into a web demo or API

### ğŸ¯ Confidence Threshold Analysis

To better understand the model's behavior across different decision thresholds, we plotted **Precision and Recall vs Confidence Threshold**.

This helps identify optimal thresholds based on the application's needs â€” for example, prioritizing **recall** in a medical setting to minimize false negatives.

![Confidence Curve](assets/densenet_confidence_curve.png)

- As expected, **precision increases** and **recall decreases** as confidence threshold rises.
- The default threshold of 0.5 (dashed line) represents a good balance, but the curve allows threshold tuning for specific use cases.

### ğŸ¯ Threshold Optimization with Youden's Index

To improve decision-making beyond the default threshold (0.5), we applied **Youden's J statistic** to determine the optimal classification threshold.

- ğŸ“Œ **Optimal Threshold (Youden's Index):** `0.7653`
- This threshold balances **recall and specificity** and is suitable for medical screening where minimizing false positives is important.

---

#### ğŸ“‹ Classification Report @ Threshold = 0.7653

| Class      | Precision | Recall | F1-score | Support |
|------------|-----------|--------|----------|---------|
| NORMAL     | 0.82      | 0.91   | 0.86     | 234     |
| PNEUMONIA  | 0.94      | 0.88   | 0.91     | 390     |
| **Accuracy**     |       |        | **0.89** | 624     |

- Macro F1: **0.89**  
- Weighted F1: **0.89**

---

![Youden Confusion Matrix](assets/youden_confusion_matrix.png)

Compared to the default threshold:
- âœ… **Precision increased**, especially for pneumonia
- âœ… **Balanced trade-off** between sensitivity and specificity
- ğŸš€ Improved overall model reliability for deployment scenarios

### ğŸ”„ Before vs After Applying Youdenâ€™s Threshold (0.7653)

We compared the model's evaluation metrics using the **default threshold (0.5)** and the **optimized threshold (0.7653)** obtained via **Youdenâ€™s Index**.

| Metric               | Threshold = 0.5   | Threshold = 0.7653 |
|----------------------|------------------|---------------------|
| **Accuracy**         | 0.87             | **0.89**            |
| **Precision (Normal)** | 0.88           | **0.82**            |
| **Recall (Normal)**    | 0.75           | **0.91**            |
| **Precision (Pneumonia)** | 0.86       | **0.94**            |
| **Recall (Pneumonia)**    | 0.94       | **0.88**            |
| **F1-Score (Normal)**    | 0.81         | **0.86**            |
| **F1-Score (Pneumonia)** | 0.90         | **0.91**            |
| **Macro F1**         | 0.85             | **0.89**            |

âœ… **Youden's threshold** improved **overall accuracy and F1-score**, especially by increasing the **recall of the NORMAL class** (reducing false positives for pneumonia).  
It's a strong alternative to the default threshold when aiming for **more reliable classification** in clinical or real-world applications.

### ğŸ§® Youdenâ€™s Index Curve

We calculated **Youdenâ€™s Index** across a range of thresholds to identify the point that best balances sensitivity (recall) and specificity.

![Youden Curve](assets/youden_index_curve.png)

- The peak occurs at **threshold = 0.7653**
- This threshold yielded the highest **Youdenâ€™s J (â‰ˆ 0.79)**, meaning it provides the most balanced classification
- This threshold was then used for post-optimization evaluation (see results above)

### ğŸ©» Grad-CAM Visualization (DenseNet121)

We used Grad-CAM to visualize the modelâ€™s attention while predicting chest X-rays using the **DenseNet121** model.

This helps us verify whether the model is focusing on medically relevant regions (lungs, opacities) when making decisions.

![Grad-CAM DenseNet](assets/gradcam_densenet.png)

**Observations:**
- âœ… **Correct NORMAL predictions** focus on clear lung regions, with lower confidence heat.
- âœ… **Correct PNEUMONIA predictions** show strong activation around infiltrates or opacities, often in lower lungs.
- âœ… The model shows consistent and localized attention, increasing trust in its predictions.

This visualization supports the model's interpretability and is helpful for clinical validation or decision support systems.

### âš ï¸ Misclassification Analysis (Grad-CAM)

We also investigated misclassified examples using Grad-CAM to understand where the model's attention was focused when it made incorrect predictions.

Below is an example where the model **incorrectly predicted "PNEUMONIA"** with high confidence (0.97), while the ground truth label was **"NORMAL"**:

![Misclassified Grad-CAM](assets/misclassified_normal_pred_pneumonia.png)

**Observation:**
- The model concentrated on a region in the **right mid-to-lower lung**, where it might have interpreted tissue texture or slight opacity as abnormal.
- This could be:
  - ğŸ”¬ A **subtle radiological feature** that resembles pneumonia (but isnâ€™t)
  - âš ï¸ A **false positive due to over-sensitivity**, especially after optimizing for high recall
  - ğŸ§  Or a **labeling inconsistency** â€” it might not be 100% "normal" (annotation noise is common in real X-ray datasets)

This highlights the importance of Grad-CAM in **interpreting model behavior** and identifying **clinical edge cases**.

### ğŸ©º Expert Review: False Positive and False Negative Analysis

To ensure clinical validity, we reviewed misclassified samples using Grad-CAM overlays to interpret model behavior, particularly focusing on false positives (FP) and false negatives (FN).

---

#### ğŸ” False Positives (Predicted: PNEUMONIA | Ground Truth: NORMAL)

![False Positives Panel](assets/misclassified_fp_panel.png)

**Clinical Interpretation:**

- The model focused on the **mid-to-lower lung zones** in most FP cases â€” common sites for pneumonia, suggesting the model is aligned with radiological intuition.
- Several cases showed **vascular markings or rib overlaps** that the model may have mistaken for infiltrates.
- In at least one case, **faint soft-tissue opacity** could potentially represent a real abnormality not labeled â€” raising the possibility of **labeling noise** in the dataset.
- These findings are **acceptable false alarms** in a triage setting where sensitivity is prioritized.

---

#### ğŸš¨ False Negatives (Predicted: NORMAL | Ground Truth: PNEUMONIA)

![False Negatives Panel](assets/misclassified_fn_panel.png)

**Clinical Interpretation:**

- Some missed cases had **diffuse or very subtle opacities** â€” likely to be overlooked without clinical correlation or lateral views.
- Grad-CAM heatmaps showed **low activation in lung zones**, indicating that the model may not have perceived enough structural irregularity to trigger a pneumonia classification.
- These false negatives reflect limitations in capturing **early or atypical presentations**, suggesting a need for:
  - Further training on mild pneumonia cases
  - Augmentation of borderline samples
  - Or integration with clinical metadata for better context

---

### ğŸ’¬ Summary

The Grad-CAM analysis provides confidence that the model is:
- Focusing on **medically relevant lung areas**
- Making **interpretable errors** consistent with clinical ambiguity
- Likely to benefit from **post-processing** (e.g., soft voting or threshold tuning) to reduce false negatives in real-world deployment

Overall, the model shows behavior **aligned with radiological patterns**, and the interpretability pipeline strengthens its potential for clinical application.

## ğŸ§  Model Architecture: CNN + Transformer Hybrid

We implemented a **hybrid deep learning model** that combines the strengths of convolutional layers (for local spatial features) and Transformer attention (for global context reasoning).

---

### ğŸ”— Architecture Flow (Sequential Hybrid)

The model structure is **sequential**, where:

1. **CNN Backbone** extracts spatial features:
   - 3 convolutional layers with increasing depth (32 â†’ 64 â†’ 128)
   - MaxPooling layers reduce spatial dimensions

2. **Transformer Encoder Block** processes reshaped CNN feature maps:
   - Reshape â†’ sequence of tokens
   - Multi-Head Self Attention + LayerNorm
   - Final embedding via Dense layer

3. **Classification Head**:
   - GlobalAveragePooling + Dense layers
   - Binary sigmoid output for pneumonia prediction

ğŸ“Œ This design allows the Transformer to operate on high-level CNN features, enabling context-aware decision-making while preserving spatial inductive biases.

---

### ğŸ“Š Architecture Diagram

![CNN + Transformer Hybrid](assets/cnn_transformer_architecture.png)

---

> âš ï¸ Note: This is a **sequential hybrid**, not a parallel architecture. The Transformer block processes CNN-derived features rather than learning from raw input in parallel.

---


## ğŸ“Š Model Performance Comparison

We evaluated three models for binary classification of chest X-rays (NORMAL vs PNEUMONIA):

| Metric               | ğŸ”¹ Basic CNN | ğŸ”¸ DenseNet121 | ğŸš€ CNN + Transformer |
|----------------------|--------------|----------------|-----------------------|
| **Test Accuracy**     | 0.87         | 0.89           | 0.88                  |
| **AUC Score**         | 0.9600       | 0.9481         | 0.9564                |
| **Pneumonia Recall**  | 0.94         | 0.88           | **0.97**              |
| **Normal Recall**     | 0.75         | **0.91**       | 0.74                  |
| **Pneumonia Precision** | 0.86       | 0.94           | 0.86                  |
| **Normal Precision**  | 0.88         | 0.82           | **0.93**              |
| **False Negatives**   | 24           | 45             | **13**                |
| **False Positives**   | 59           | **22**         | 62                    |

---

### ğŸ§  Interpretation

- âœ… **CNN + Transformer** model achieved **highest AUC (0.9564)** and **best recall for pneumonia (0.97)**, making it ideal for **early-stage triage or screening** tasks.
- ğŸ”¸ **DenseNet121** provided the **most balanced performance**, with strong precision and recall for both classes and the **lowest false positive rate**.
- ğŸ”¹ The **basic CNN** performed surprisingly well for its simplicity, with strong pneumonia recall (0.94) and overall AUC of 0.96, but suffered more false positives.

---

### ğŸ” Visual Evaluation (CNN + Transformer)

**ROC Curve:**

![ROC Curve - CNN+Transformer](assets/roc_cnn_transformer.png)

**Confusion Matrix:**

![Confusion Matrix - CNN+Transformer](assets/cm_cnn_transformer.png)

---

### ğŸ©º Recommendation

| Use Case                         | Suggested Model        |
|----------------------------------|------------------------|
| **Clinical Triage / Early Warning** | ğŸš€ CNN + Transformer |
| **Balanced Diagnosis Model**     | ğŸ”¸ DenseNet121         |
| **Resource-Constrained Deployment** | ğŸ”¹ Basic CNN         |

---

### ğŸ“Œ Notes

- All models were trained and tested on the **Chest X-ray (Pneumonia)** dataset.
- Each was evaluated using accuracy, precision, recall, AUC, and confusion matrix.
- Grad-CAM visualizations were used to interpret model focus for both correct and misclassified cases.
- ROC & confusion plots were saved under `/assets` for comparison.

### ğŸ”„ Retraining Results (Resume from Checkpoint)

After continuing training the CNN + Transformer model from the saved checkpoint (`cnn_transformer_best.keras`) for 100 more epochs, we observed improved generalization:

- âœ… **AUC (NORMAL)** increased from 0.9482 â†’ **0.9550**
- âœ… **AUC (PNEUMONIA)** increased from 0.9482 â†’ **0.9550**
- âœ… **Normal Recall** improved from 0.74 â†’ **0.79**
- âœ… **Pneumonia Precision** improved from 0.86 â†’ **0.89**
- ğŸ” Slight trade-off in Pneumonia Recall (0.97 â†’ 0.95), but overall better balance

This shows that **resuming from a strong checkpoint** and training further can help:
- Reduce underfitting in early stages
- Sharpen model attention (confirmed by Grad-CAM++)
- Improve AUC and decision calibration

ğŸ§ª We recommend fine-tuning in 2 stages:
1. Train to baseline â†’ Save best checkpoint
2. Resume from best checkpoint â†’ Boost generalization


## ğŸ”¬ Grad-CAM++ Visualizations (CNN + Transformer)

To better understand what the CNN + Transformer model is focusing on during predictions, we applied **Grad-CAM++** on correctly classified test images.

This helped us visualize **model attention across lung fields**, especially in high-confidence cases.

---

### âœ… Results: Examples

![GradCAM++ CNN+Transformer](assets/gradcampp_cnn_transformer.png)

| True Label | Predicted | Confidence | Observation |
|------------|-----------|------------|-------------|
| **NORMAL** | NORMAL    | 0.18       | Weak, scattered activation â€” no strong features detected |
| **NORMAL** | NORMAL    | 0.44       | Slight attention near ribs/clavicle, not lung infiltrates |
| **PNEUMONIA** | PNEUMONIA | 0.98     | Strong focus in lower/mid-lung â€” expected pneumonia zone |
| **PNEUMONIA** | PNEUMONIA | 1.00     | Whole-lung saturated activation â€” strong evidence, but may indicate overconfidence in severe cases |

---

### ğŸ©º Clinical Insight

- **NORMAL cases**: Weak or localized activation â†’ suggests model does not falsely over-interpret normal structures.
- **PNEUMONIA cases**: Strong focus on lower or central lung regions aligns well with radiological findings.
- In very confident predictions (1.00), the activation sometimes spreads across the entire lung field â€” typical for severe infections but worth reviewing further.

---

### ğŸ§  Why Grad-CAM++?

Grad-CAM++ improves upon Grad-CAM by:
- Using **second-order gradients**
- Producing **sharper, better localized heatmaps**
- Revealing **fine-grained** decision cues, especially in medical imaging

---

### ğŸ›  Next Step

We plan to:
- Run Grad-CAM++ on **misclassified cases** (false positives & false negatives)
- Compare with basic Grad-CAM and Score-CAM for further validation

## ğŸ” AI-Assisted Case Review Summary

To evaluate the modelâ€™s clinical plausibility, we manually inspected a sample of **Grad-CAM visualizations** from both correctly classified and misclassified test cases. We reviewed:

- âœ… Focus regions (e.g., lung bases, consolidations)
- âœ… Misinterpretations (e.g., overactivation on ribs or artifacts)
- âœ… Common failure modes (e.g., subtle opacity missed)

The following table summarizes selected examples from the modelâ€™s predictions:

| ğŸ§ª Case | âœ… True Label | ğŸ¤– Prediction | ğŸ“Š Confidence | ğŸ”¥ Grad-CAM Focus | ğŸ©º Clinical Interpretation |
|--------|--------------|----------------|----------------|--------------------|-----------------------------|
| #1     | NORMAL        | PNEUMONIA      | 0.91           | Lower left lobe     | Misclassified due to overexposure artifact |
| #2     | PNEUMONIA     | PNEUMONIA      | 0.98           | Bilateral lower zones | Matches clinical findings (classic presentation) |
| #3     | PNEUMONIA     | NORMAL         | 0.38           | Sparse / unfocused  | False negative â€” opacity was subtle |
| #4     | COVID19       | PNEUMONIA      | 0.82           | Perihilar region     | Overlap with viral pneumonia pattern |
| #5     | TUBERCULOSIS  | TUBERCULOSIS   | 0.95           | Right upper lobe     | Correctly detects cavitary pattern |
| #6     | NORMAL        | NORMAL         | 0.07           | Background (non-lung) | Correct â€” no abnormal focus seen |

> ğŸ§  *Grad-CAM visualization supports model transparency and helped identify common failure patterns.*

---

## ğŸ« Grad-CAM Visualization on Real Hospital Pneumonia & Normal Cases

To validate the modelâ€™s clinical applicability, we applied **Grad-CAM** to **real anonymized hospital chest X-rays** (not part of the training set). These examples highlight how the model localizes pathology on unseen, real-world data.

<table>
  <tr>
    <td align="center"><strong>âœ… Normal Chest X-ray</strong><br><br><img src="assets/normal_real_gradcam.png" width="300"/></td>
    <td align="center"><strong>ğŸ¦  Pneumonia Chest X-ray</strong><br><br><img src="assets/pneumonia_real_gradcam.png" width="300"/></td>
  </tr>
</table>

> ğŸ” **Observation**:  
> - **Normal**: Low model activation across the lung field.  
> - **Pneumonia**: Strong Grad-CAM activation in the lower lobes, consistent with expected consolidation zones.

> ğŸ©º *These activations were reviewed and confirmed as clinically reasonable by radiologic interpretation.*

---

âš ï¸ Hospital data was used strictly for internal validation and remains confidential.

## ğŸ“ˆ Swin Transformer Results on 4-Class Dataset

We evaluated the **Swin Transformer** on a diverse chest X-ray dataset containing **4 classes**:

- ğŸŸ© **COVID19**
- ğŸŸ¦ **NORMAL**
- ğŸŸ¥ **PNEUMONIA**
- ğŸŸ¨ **TUBERCULOSIS**

### ğŸ§  ROC Curve

![ROC Curve â€“ Swin Transformer (4-Class)](assets/swin_roc_4class.png)

> **AUC Scores:**
> - **COVID19**: `1.00`
> - **NORMAL**: `0.94`
> - **PNEUMONIA**: `0.98`
> - **TUBERCULOSIS**: `1.00`

---

### ğŸ“Š Confusion Matrix

![Confusion Matrix â€“ Swin Transformer (4-Class)](assets/swin_confusion_4class.png)

> âœ… The model excels at **COVID19**, **PNEUMONIA**, and **TUBERCULOSIS**  
> âš ï¸ Some **NORMAL** cases are misclassified as **PNEUMONIA**

---

> ğŸ“Œ *This experiment demonstrates the Swin Transformerâ€™s strong ability to generalize across complex chest X-ray patterns including infectious diseases like COVID-19 and tuberculosis.*

## ğŸ§  Grad-CAM Visualizations â€“ Swin Transformer (4-Class)

To interpret the Swin Transformerâ€™s decision-making, we visualized **Grad-CAM overlays** for predictions on the **COVID-19 + Pneumonia chest X-ray dataset**.

These heatmaps reveal **where the model focuses** when making a classification.

<p align="center">
  <img src="assets/swin_gradcam_examples.png" alt="Swin Transformer Grad-CAM overlays" width="600">
</p>

---

### ğŸ” Clinical Observations

| Class           | Model Focus Area                     | Verdict         |
|------------------|---------------------------------------|------------------|
| **Pneumonia**     | Lower lobes / patchy infiltrates      | âœ… Consistent     |
| **COVID-19**      | Bilateral peripheral regions          | âœ… Expected       |
| **Tuberculosis**  | Mid-upper lung fields                 | âœ… Realistic      |
| **NORMAL**        | Mostly clear lung fields              | âœ… Clean focus    |
| **Misclassifications** | Some off-lung attention, possibly due to artifacts or mild opacity | âš ï¸ Worth Reviewing |

> ğŸ“Œ **Note**: All Grad-CAMs are from *unseen test data* and demonstrate model explainability across correct and incorrect predictions.

---

## ğŸ§ª Robustness Evaluation under Noisy & Degraded Conditions

To simulate real-world clinical environments, we tested the trained **Swin Transformer** model on a variety of augmented chest X-ray conditions:

| Noise Type         | Accuracy (%) | Result       |
|--------------------|---------------|--------------|
| âœ… **Clean**         | 70.17%        | ğŸ”µ Baseline   |
| ğŸŒ«ï¸ Gaussian Noise    | 67.44%        | ğŸŸ¡ Slight drop |
| ğŸŒ Overexposed       | **72.24%**    | ğŸŸ¢ Robust      |
| ğŸŒš Underexposed      | 66.41%        | ğŸŸ¡ Decreased   |
| ğŸŒ€ Blurred           | 58.88%        | ğŸ”´ Sensitive   |
| ğŸ”» Low-Resolution    | 59.01%        | ğŸ”´ Sensitive   |

<div align="center">
  <img src="assets/noise_robustness_barplot.png" width="70%" alt="Model Accuracy under Noise Conditions">
</div>

### ğŸ” Key Observations:
- The model **maintains performance** under slight brightness or noise changes.
- **Blur and resolution degradation** significantly reduce accuracy â€” likely due to loss of fine structural cues.
- Suggests a need for:
  - Image quality pre-checks during deployment.
  - Training-time augmentations to improve generalization.

> ğŸ’¬ _This analysis adds an extra layer of trust and practicality, especially for **deployment in resource-variable hospital settings**._

---

## ğŸ¯ Performance After Applying Focal Loss

We re-trained the **Swin Transformer** using **Focal Loss** to address class imbalance and improve robustness. The results show notable improvements in precision, especially for minority classes like COVID19 and Tuberculosis.

### ğŸ“‹ Classification Report

| Class            | Precision | Recall | F1-Score | Support |
|------------------|-----------|--------|----------|---------|
| **COVID19**      | 0.93      | 1.00   | 0.96     | 106     |
| **NORMAL**       | 0.81      | 0.90   | 0.85     | 234     |
| **PNEUMONIA**    | 0.94      | 0.85   | 0.89     | 390     |
| **TUBERCULOSIS** | 1.00      | 0.98   | 0.99     | 41      |

- **Overall Accuracy**: `0.89`
- **Macro Average**: Precision = `0.92` | Recall = `0.93` | F1 = `0.92`
- **Weighted Average**: Precision = `0.90` | Recall = `0.89` | F1 = `0.90`

---

### ğŸ§¾ Confusion Matrix

<div align="center">
  <img src="assets/cm_swin_after_fl.png" width="70%" alt="Model Accuracy under Noise Conditions">
</div>
---

### ğŸ”¬ Insights

- âœ… **COVID19 and Tuberculosis** cases were detected with near-perfect precision and recall.
- ğŸ“‰ **Pneumonia** recall slightly dropped (85%) but precision improved, reducing false positives.
- ğŸ“ˆ **NORMAL** class performance improved with fewer cases misclassified as Pneumonia.
- ğŸ’¡ **Focal Loss** effectively focuses on hard-to-classify examples and improves minority class handling.

> ğŸ§  These results make the model more clinically viable, especially for rare or critical conditions.


